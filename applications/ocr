#!/bin/bash
# ocr: Perform OCR on an image using a vision-language model
# Usage: ocr [-l] <image_path> [additional_instructions]
#   -l : use larger model (8B parameters)

VL_MODEL="qwen3-vl:2b-instruct-q8_0"

if [ "$1" = "-l" ]; then
  VL_MODEL="qwen3-vl:8b-instruct-q8_0"
  shift
fi

PATH_INPUT=$(realpath "$1")

read -r -d '' INSTRUCTION <<'EOF'
- Perform OCR on this image and extract the textual content
- If Markdown-like styling (e.g., headers, lists, emphasis) is detected, output in proper Markdown format. Also, don't put it in code blocks (```).
- If TeX mathematical expressions appear, reconstruct and output them as TeX code
  - Enclose the mathematical content in \begin{align}...\end{align} and provide the output; no other text is required
  - \boldsymbol may be written as \bm
- For other structured content (tables, code blocks, etc.), infer a suitable format and output accordingly
EOF

is_valid_image_path() {
  local path="$1"
  [ -f "$path" ] || return 1
  case "$path" in
    *.png|*.jpg|*.jpeg) return 0;;
    *) return 1;;
  esac
}

if ! is_valid_image_path "$PATH_INPUT"; then
  echo "Error: Invalid argument. Please provide a path to a valid image file." >&2
  exit 1
fi

if [ $# -gt 1 ]; then
  shift
  for instruction in "$@"; do
    INSTRUCTION="${INSTRUCTION}- $instruction\n"
  done
fi

llm -m "$VL_MODEL" -a "$PATH_INPUT" -- "$INSTRUCTION" | pbcopy | spinner "Processing OCR..."
echo "Output copied to clipboard."
